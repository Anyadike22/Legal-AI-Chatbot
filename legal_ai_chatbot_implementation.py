# -*- coding: utf-8 -*-
"""Legal_AI_Chatbot_Implementing_bigscience_T0pp_LLM_with_PyTorch,_Hugging_Face_Marktechpost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xg992ld9ErcFVrn32aZ1pCftC1AEz-YG
"""

!pip install transformers sentencepiece datasets faiss-cpu langchain openai tiktoken spacy nltk
!python -m spacy download en_core_web_sm

"""# Importing and Loading Pretrained Transformer model and it's corresponding tokenizer from the transformer library by Hugging face

T0pp (T0 Prime Plus) is an open-source model trained by BigScience and is designed for zero-shot and few-shot text generation tasks, meaning it can answer prompts without additional fine-tuning.
It is based on the T5 (Text-to-Text Transfer Transformer) architecture, meaning it expects text input and produces text output.
"""

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model_name = "bigscience/T0pp"  # Open-source and available
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

"""#Further Preprocessing
This script below  is to preprocess legal text for further analysis, such as text classification, NLP tasks, or legal document processing. It uses the spaCy library for linguistic processing and re (Regular Expressions) for text cleaning.

This script is designed to extract named entities from a given text using spaCy's Named Entity Recognition (NER). It identifies important entities such as organizations, dates, and legal terms from the text.

Processing Steps:
Converts to lowercase.
Removes punctuation.
Tokenizes text.
Removes stopwords.
Lemmatizes words.
"""

import spacy
import re

nlp = spacy.load("en_core_web_sm")

def preprocess_legal_text(text):
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)  # Remove extra spaces
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)  # Remove special characters
    doc = nlp(text)
    tokens = [token.lemma_ for token in doc if not token.is_stop]  # Lemmatization
    return " ".join(tokens)

sample_text = "The contract is valid for 10 years, terminating on December 31, 2030."
print(preprocess_legal_text(sample_text))

"""# Extracting named entities from the given text using spaCy's Named Entity Recognition (NER)

This script is designed to extract named entities from a given text using spaCy's Named Entity Recognition (NER). It identifies important entities such as organizations, dates, and legal terms from the text.

Extracts important legal entities (e.g., company names, contracts, dates).
✅ Automates legal text analysis (e.g., contract processing, case law summaries).
✅ Can be expanded to detect laws (LAW label) with a more advanced legal NLP model.
"""

import spacy

def extract_legal_entities(text):
    doc = nlp(text)
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    return entities

sample_text = "Apple Inc. signed a contract with Microsoft on June 15, 2023."
print(extract_legal_entities(sample_text))

import torch

"""# Embeding text using a transformer model
This script embeds legal text using a transformer model, indexes the embeddings with FAISS, and retrieves the most relevant legal document for a given query. Let's break it down step by step.

Tokenizes input text and converts it into tensors for the model.
Uses with torch.no_grad() to disable gradient computation (speeds up inference).
Extracts the last_hidden_state from the model’s output.
Averages the token embeddings (mean(dim=1)) to get a single vector representation for the entire text.
Converts the tensor to a NumPy array for compatibility with FAISS.

# Summary: What Does This Script Do?
Loads a pretrained transformer model (all-MiniLM-L6-v2) for sentence embeddings.
Converts legal documents into embeddings (dense vector representations).
Stores the embeddings in a FAISS index for fast similarity search.
Embeds a query and retrieves the most relevant legal document using nearest neighbor search.

"""

import faiss
import numpy as np
import torch
from transformers import AutoModel, AutoTokenizer

embedding_model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
embedding_tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")

def embed_text(text):
    inputs = embedding_tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        output = embedding_model(**inputs)
    embedding = output.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Ensure 1D vector
    return embedding

legal_docs = [
    "A contract is legally binding if signed by both parties.",
    "An NDA prevents disclosure of confidential information.",
    "A non-compete agreement prohibits working for a competitor."
]

doc_embeddings = np.array([embed_text(doc) for doc in legal_docs])

print("Embeddings Shape:", doc_embeddings.shape)  # Should be (num_samples, embedding_dim)

index = faiss.IndexFlatL2(doc_embeddings.shape[1])  # Dimension should match embedding size
index.add(doc_embeddings)

query = "What happens if I break an NDA?"
query_embedding = embed_text(query).reshape(1, -1)  # Reshape for FAISS
_, retrieved_indices = index.search(query_embedding, 1)

print(f"Best matching legal text: {legal_docs[retrieved_indices[0][0]]}")

"""# Checks whether a GPU (CUDA) is available for PyTorch to use."""

import torch
print("GPU Available:", torch.cuda.is_available())

"""# Takes a legal query as input (e.g., "What happens if I break an NDA?").
Encodes the query into token IDs using tokenizer(), preparing it for the model.
Generates a response using model.generate() with a max length of 100 tokens.
Decodes the model's output back into readable text using tokenizer.decode()
"""

def legal_chatbot(query):
    inputs = tokenizer(query, return_tensors="pt", padding=True, truncation=True)
    output = model.generate(**inputs, max_length=100)
    return tokenizer.decode(output[0], skip_special_tokens=True)

query = "What happens if I break an NDA?"
print(legal_chatbot(query))